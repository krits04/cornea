{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Protein classification using Random Forest </center></h1>\n",
    "\n",
    "Using the new dataset with environment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "import seaborn as sns; sns.set(style='ticks', font='serif')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/kriti/Documents/BNL/random_forests/training_k3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make header consistent throughout the files by running the following command in the terminal\n",
    "\n",
    "```\n",
    "var='\"\",\"cmi.m.Var1\",\"cmi.m.Var2\",\"cmi.m$value\",\"ecmi.m$value\",\"cc.m$value\",\"ecc.m$value\",\"cp.m$value\",\"ecp.m$value\",\"cp1.m$value\",\"ecp1.m$value\",\"cp2.m$value\",\"ecp2.m$value\",\"hcm.m$value\",\"ehcm.m$value\",\"rsa.m$value\",\"ersa.m$value\",\"scm.m$value\",\"escm.m$value\",\"ssp.m$value\",\"essp.m$value\",\"inf.m$value\"'\n",
    "for i in $( ls *.csv ); do\n",
    "    sed -i \"1s/.*/$var/\" $i\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + \"1a2k_k3_df.csv\", engine= 'python')\n",
    "\n",
    "df_x = (df[[\"cmi.m$value\",\"cc.m$value\",\"cp.m$value\",\"cp1.m$value\", \"cp2.m$value\",\"hcm.m$value\",\"rsa.m$value\",\n",
    "            \"scm.m$value\",\"ssp.m$value\", \"ecc.m$value\", \"ecmi.m$value\", \"ecp.m$value\", \"ecp1.m$value\", \"ecp2.m$value\", \"ehcm.m$value\", \"ersa.m$value\", \"escm.m$value\", \"essp.m$value\"]])\n",
    "\n",
    "df_y = (df[[\"inf.m$value\"]])\n",
    "\n",
    "df_x.shape, df_y[df_y[\"inf.m$value\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob(data_dir + \"*.csv\")\n",
    "\n",
    "for file_name in file_list:\n",
    "    \n",
    "        df_temp = pd.read_csv(file_name)\n",
    "        df_xn = (df_temp[[\"cmi.m$value\",\"cc.m$value\",\"cp.m$value\",\"cp1.m$value\", \"cp2.m$value\",\"hcm.m$value\",\"rsa.m$value\",\n",
    "            \"scm.m$value\",\"ssp.m$value\", \"ecc.m$value\", \"ecmi.m$value\", \"ecp.m$value\", \"ecp1.m$value\", \"ecp2.m$value\", \"ehcm.m$value\", \"ersa.m$value\", \"escm.m$value\", \"essp.m$value\"]])\n",
    "        df_yn = (df_temp[[\"inf.m$value\"]])\n",
    "        df_x = df_x.append(df_xn, ignore_index=True)\n",
    "        df_y = df_y.append(df_yn, ignore_index=True)\n",
    "        print(\"'%-40s' file read with %i True\" %(file_name, df_temp[df_temp[\"inf.m$value\"] == 1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x1 = df_x[df_y['inf.m$value']==0] # Dataframe x-axis with all zeros\n",
    "df_y1 = df_y[df_y['inf.m$value']==0] # Dataframe y-axis with all zeros\n",
    "\n",
    "df_x2 = df_x[df_y['inf.m$value']==1] # Dataframe x-axis with all ones\n",
    "df_y2 = df_y[df_y['inf.m$value']==1] # Dataframe y-axis with all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x1.shape, df_y1.shape, df_x2.shape, df_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose random indices from df_x1.index with length = 5*length of df_x2\n",
    "\n",
    "rind = np.random.choice(np.array(df_x1.index), size=5*len(df_x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_x1.loc[rind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x3 = df_x1.loc[rind]\n",
    "df_y3 = df_y1.loc[rind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xc = pd.concat([df_x3, df_x2], ignore_index=True)\n",
    "df_yc = pd.concat([df_y3, df_y2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xc.shape, df_yc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = (df_xc.values)\n",
    "y = (df_yc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(x))):\n",
    "#     x[i,0] = dict_var12[x[i,0]]\n",
    "#     x[i,1] = dict_var12[x[i,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x)\n",
    "rescaledX = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rescaledX, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)\n",
    "\n",
    "lengths = [len(lst) for lst in random_grid.values()]\n",
    "\n",
    "combs=1\n",
    "for i in range(len(lengths)):\n",
    "    combs *= lengths[i]\n",
    "print('Total number of combinations: {:16d}'.format(combs))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Base model to tune\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                               scoring='f1', n_iter = 100, cv = 5, verbose=1, \n",
    "                               random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "time_start = time.time()\n",
    "rf_random.fit(X_train, y_train)\n",
    "e = int(time.time() - time_start) # elapsed time\n",
    "print(\"Time taken in fitting: {:02d}h:{:02d}m:{:5.2f}s\".format(e//3600, e % 3600 // 60, e % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = best_random.score(X_test, y_test)\n",
    "print(\"Best Random model Accuracy: %.2f%%\" % (random_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further fine-tuning near the best fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "cmap = sns.cubehelix_palette(light=0.98, as_cmap=True)\n",
    "unsuv_cm = pd.DataFrame(cm)\n",
    "sns.heatmap(unsuv_cm, annot=True,annot_kws={\"size\": 16}, cmap=cmap, fmt='d')# font size\n",
    "plt.xlabel(\"Predicted Class\", fontsize=20, labelpad=20)\n",
    "plt.ylabel(\"True Class\", fontsize=20, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('conf_matrix_new.svg', format= 'svg')\n",
    "fig.savefig('conf_matrix_leaving_new.eps', format= 'eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 40],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [4,6,8],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [1600, 1800, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring='f1',\n",
    "                           cv = 5, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "grid_search.fit(X_train, y_train);\n",
    "e = int(time.time() - time_start) # elapsed time\n",
    "\n",
    "print(\"Fitting Time: {:02d}h:{:02d}m:{:5.2f}s\".format(e//3600, e % 3600 // 60, e % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_search, 'RF_random_grid_model_with_env_model_kernel_3_new.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Model Parameters:\\n')\n",
    "pprint(final_model.get_params())\n",
    "print('\\n')\n",
    "grid_final_accuracy = final_model.score(X_test, y_test)\n",
    "print(\"Grid Final Accuracy: %.2f%%\" % (grid_final_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "cmap = sns.cubehelix_palette(light=0.98, as_cmap=True)\n",
    "unsuv_cm = pd.DataFrame(cm)\n",
    "sns.heatmap(unsuv_cm, annot=True,annot_kws={\"size\": 16}, cmap=cmap, fmt='d')# font size\n",
    "plt.xlabel(\"Predicted Class\", fontsize=20, labelpad=20)\n",
    "plt.ylabel(\"True Class\", fontsize=20, labelpad=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('conf_matrix_f1_kernel_3.svg', format= 'svg')\n",
    "fig.savefig('conf_matrix_f1_kernel_3.eps', format= 'eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in final_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(final_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = 18\n",
    "graph= plt.figure(figsize=(10,7))\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(X_train.shape[1])[0:n_feature], importances[indices[0:n_feature]],\n",
    "       color=\"royalblue\", yerr=std[indices[0:n_feature]], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1])[0:n_feature], indices[0:n_feature])\n",
    "plt.xlim([-1, n_feature])\n",
    "plt.show()\n",
    "graph.savefig('feature_importace_kernel_3.svg', format= 'svg')\n",
    "graph.savefig('feature_importace_kernel_3.eps', format= 'eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_graph= plt.figure()\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "auc_graph.savefig('auc_roc_kernel_3.svg', format= 'svg')\n",
    "auc_graph.savefig('auc_roc_kernel_3.eps', format= 'eps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on \"data_frames_01102018/3i4r_final_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/lab6nb/random_forests/test_3.15/\"\n",
    "df = pd.read_csv(data_dir + \"3i4r_k3_15_df.csv\")\n",
    "\n",
    "df_x3i4r = (df[[\"cmi.m$value\",\"cc.m$value\",\"cp.m$value\",\"cp1.m$value\", \"cp2.m$value\",\"hcm.m$value\",\"rsa.m$value\",\n",
    "            \"scm.m$value\",\"ssp.m$value\", \"ecc.m$value\", \"ecmi.m$value\", \"ecp.m$value\", \"ecp1.m$value\", \"ecp2.m$value\", \"ehcm.m$value\", \"ersa.m$value\", \"escm.m$value\", \"essp.m$value\"]])\n",
    "\n",
    "df_y3i4r = (df[[\"inf.m$value\"]])\n",
    "\n",
    "df_x3i4r.shape, df_y3i4r[df_y3i4r[\"inf.m$value\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_3i4r = np.array(df_x3i4r)\n",
    "ytest_3i4r = np.array(df_y3i4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_xtest_3i4r = scaler.transform(xtest_3i4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_3i4r = ytest_3i4r.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_3i4r = final_model.predict(rsc_xtest_3i4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = final_model.predict_proba(rsc_xtest_3i4r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test_prob[(ytest_3i4r == 0) & (ypred_3i4r == 1)][:,1])\n",
    "sns.distplot(test_prob[(ytest_3i4r == 1) & (ypred_3i4r == 1)][:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "predicted_proba = final_model.predict_proba(rsc_xtest_3i4r)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape, ytest_3i4r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ytest_3i4r, predicted)#ypred_3i4r)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "cmap = sns.cubehelix_palette(light=0.98, as_cmap=True)\n",
    "unsuv_cm = pd.DataFrame(cm)\n",
    "sns.heatmap(unsuv_cm, annot=True,annot_kws={\"size\": 16}, cmap=cmap, fmt='d')# font size\n",
    "plt.xlabel(\"Predicted Class\", fontsize=20, labelpad=20)\n",
    "plt.ylabel(\"True Class\", fontsize=20, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest_3i4r, predicted))#ypred_3i4r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(predicted, columns=['prediction']).to_csv('prediction_5yvt_k9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
